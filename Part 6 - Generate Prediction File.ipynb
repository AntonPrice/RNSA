{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6 - Generate Prediction File\n",
    "\n",
    "Now creating the prediction file.  First is to generate the prediction dataframe and then create a file from this dataframe.\n",
    "\n",
    "The steps here are as follows -\n",
    "1. Parse through dataframe and get patientids\n",
    "2. Generate prediction on patient id\n",
    "3. Create bounding boxes from prediction\n",
    "4. Generate box confidences (avg pool of box region)\n",
    "5. Encode bounding boxes in correct format\n",
    "6. Generate output file \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pydicom\n",
    "\n",
    "#Import previously created functions\n",
    "from rnsa_funcs import *\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import itertools\n",
    "\n",
    "#Remove GPUs\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"    \n",
    "\n",
    "#Import Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "\n",
    "#Import Keras\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from keras.layers import Activation, ZeroPadding2D, AveragePooling2D, Add, Concatenate, SeparableConv2D\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, Input, DepthwiseConv2D\n",
    "from keras.layers import GlobalAveragePooling2D, multiply, ZeroPadding2D, MaxPooling2D, Reshape, add, Conv2DTranspose\n",
    "#from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.models import Sequential, Model\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.models import load_model\n",
    "from keras.initializers import glorot_uniform\n",
    "#from keras.models import load_model\n",
    "from keras_applications.imagenet_utils import _obtain_input_shape \n",
    "from keras.callbacks import ModelCheckpoint\n",
    "#import sklearn\n",
    "import sklearn as sk\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from skimage import measure\n",
    "\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Unet_DS5 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuring to try to prevent OOM errors\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup path locations\n",
    "BASE_PATH = 'G:\\Kaggle\\RSNA_Comp'\n",
    "TRAIN_PATH_RAW = 'G:\\Kaggle\\RSNA_Comp\\stage_1_train_images'\n",
    "#TEST_PATH_RAW = 'G:\\Kaggle\\RSNA_Comp\\stage_1_test_images'\n",
    "TRAIN_PATH_CLEAN = 'G:\\Kaggle\\RSNA_Comp\\\\train_image_clean'\n",
    "TEST_PATH_CLEAN = 'G:\\Kaggle\\RSNA_Comp\\\\test_image_clean'\n",
    "MODEL_PATH = 'G:\\Kaggle\\RSNA_Comp\\\\models'\n",
    "\n",
    "TEST_PATH_RAW = 'G:\\Kaggle\\RSNA_Comp\\stage_2_test_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dataframes from csvs\n",
    "#train_frame = pd.read_csv(os.path.join(TRAIN_PATH_CLEAN, 'train_frame.csv'))\n",
    "#val_1_frame = pd.read_csv(os.path.join(TRAIN_PATH_CLEAN, 'val_1_frame.csv'))\n",
    "#val_2_frame = pd.read_csv(os.path.join(TRAIN_PATH_CLEAN, 'val_2_frame.csv'))\n",
    "#test_frame = pd.read_csv(os.path.join(TEST_PATH_CLEAN, 'test_frame.csv'))\n",
    "#train_labels = pd.read_csv(os.path.join(BASE_PATH, 'stage_1_train_labels.csv'))\n",
    "test_frame = pd.read_csv(os.path.join(BASE_PATH, 'stage_2_sample_submission.csv'))\n",
    "\n",
    "\n",
    "\n",
    "#Import new binary frames\n",
    "#train_frame_new = pd.read_csv(os.path.join(TRAIN_PATH_CLEAN, 'train_frame_bin.csv'))\n",
    "#val_1_frame_new = pd.read_csv(os.path.join(TRAIN_PATH_CLEAN, 'val_1_frame_bin.csv'))\n",
    "\n",
    "#Import train labels for drawing bounding boxes\n",
    "full_labels = pd.read_csv(os.path.join(TRAIN_PATH_CLEAN, 'train_lab_df.csv'))\n",
    "#val_1_lab_df = pd.read_csv(os.path.join(TRAIN_PATH_CLEAN, 'val_1_labels_tf.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mod = test_block()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"unetv6.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_mod.compile(optimizer = Adam(0.0001), loss = iou_bce_loss, metrics = [mean_iou])\n",
    "test_mod.compile(optimizer = Adam(0.0001), loss = dice_bce_loss, metrics = [mean_dice])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mod.load_weights(os.path.join(MODEL_PATH, model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Input_img_batch_BB_DS(df, label_df, pred = 0, frm_type = 0):\n",
    "    #Setup Variables\n",
    "    m = df.shape[0]\n",
    "    out_img_batch = np.zeros((m, 256, 256))\n",
    "    out_img_y = np.zeros((m, 256, 256))\n",
    "    \n",
    "    \n",
    "    for i in range(m) :\n",
    "        #Splitting patient id out for querying the labels\n",
    "        if frm_type == 0 : \n",
    "            patient_id = df.iat[i, 6]\n",
    "        else :\n",
    "            patient_id = df.iat[i, 0]\n",
    "            \n",
    "            \n",
    "        img_filename = patient_id + '.npy'\n",
    "        \n",
    "        img = np.load(os.path.join(TEST_PATH_CLEAN, img_filename))\n",
    "        \n",
    "        #img2 = resize(img, (224, 224), mode='reflect')\n",
    "\n",
    "        #Transform image to normalize for model processing\n",
    "        out_img_batch[i] =  resize(img, (256, 256), mode='reflect')\n",
    "        \n",
    "        \n",
    "        #Getting labels\n",
    "        if pred == 0 :\n",
    "                pat_labels = label_df[label_df['patientId'] == patient_id]\n",
    "                pat_labels = pat_labels.reset_index()\n",
    "                out_lab = np.zeros((1024, 1024))\n",
    "            \n",
    "                for row in pat_labels.iterrows():\n",
    "                    dat = row[1]\n",
    "                    x_min = np.around(dat['x']).astype(int)\n",
    "                    y_min = np.around(dat['y']).astype(int)\n",
    "                \n",
    "                    w = np.around(dat['width']).astype(int)\n",
    "                    h = np.around(dat['height']).astype(int)\n",
    "                \n",
    "                    for x in range(w):\n",
    "                        x_pix = np.clip(x + x_min, 0, 1023)\n",
    "                        for y in range(h):\n",
    "                            y_pix = np.clip(y + y_min, 0, 1023)\n",
    "                            out_lab[y_pix, x_pix] = 1.0\n",
    "                        \n",
    "                out_img_y[i] = resize(out_lab, (256, 256), mode='reflect')\n",
    "        \n",
    "        \n",
    "\n",
    "    out_img_batch = out_img_batch.reshape(m, 256, 256, 1)\n",
    "    if pred != 0:\n",
    "        return out_img_batch\n",
    "    else :\n",
    "        out_y = out_img_y.reshape(m, 256, 256, 1)\n",
    "        return out_img_batch, out_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pred_batch(df_in, model, msk_thresh = 0.6, area_thresh = 2500, inverse = 0, inf_dict = None):\n",
    "    #Setup parameters + variables\n",
    "    df_preds_out = pd.DataFrame(columns=(['patientId', 'x', 'y', 'width', 'height', 'area', 'confidence']))\n",
    "    m = df_in.shape[0]\n",
    "    \n",
    "    #Generate predictions\n",
    "    pred_img = Input_img_batch_BB_DS(df_in, full_labels, pred = 1, frm_type = inverse)\n",
    "    \n",
    "    predict_small = model.predict(pred_img)\n",
    "    predict = resize(predict_small, (m, 1024, 1024, 1), mode='reflect')\n",
    "\n",
    "    #For every patient generate prediction boxes\n",
    "    for i in range(m):\n",
    "        if inverse == 0 :\n",
    "            patientid = df_in.iat[i, 6]        \n",
    "        else :\n",
    "            patientid = df_in.iat[i, 0]  \n",
    "            \n",
    "            \n",
    "        pred_new = predict[i, :, :, 0]\n",
    "\n",
    "        # threshold predicted mask\n",
    "        comp1 = pred_new[:, :] > msk_thresh\n",
    "        comp = measure.label(comp1)\n",
    "        \n",
    "        if pred_new.max() > msk_thresh : \n",
    "            for region in measure.regionprops(comp):\n",
    "                y, x, y2, x2 = region.bbox\n",
    "                height = y2 - y\n",
    "                width = x2 - x\n",
    "        \n",
    "                #Generate stats about prediction - area and avg pool\n",
    "                conf = np.mean(pred_new[y:y+height, x:x+width])\n",
    "                area = height * width\n",
    "            \n",
    "                #Generate pred dataframe\n",
    "                if area >= area_thresh :\n",
    "                    #If not inverse flag do not transform\n",
    "                    if inverse == 0 :\n",
    "                        df_dict = {'patientId' : patientid, \n",
    "                               'x' : x,\n",
    "                               'y' : y,\n",
    "                               'width' : width,\n",
    "                               'height' : height,\n",
    "                               'area' : area,\n",
    "                               'confidence' : conf}\n",
    "                        df_preds = pd.DataFrame(df_dict, index=[0])\n",
    "                        df_preds_out = df_preds_out.append(df_preds, ignore_index=True)\n",
    "                    \n",
    "                    #Otherwise do inverse transform to original image    \n",
    "                    else :\n",
    "                        box_arr = np.array([x, y, width, height])\n",
    "                \n",
    "                        #Perform inverse BB transform\n",
    "                        box_out = invert_bb_convert(box_arr, inf_dict[patientid])\n",
    "                \n",
    "                        df_dict = {'patientId' : patientid, \n",
    "                               'x' : box_arr[0],\n",
    "                               'y' : box_arr[1],\n",
    "                               'width' : box_arr[2],\n",
    "                               'height' : box_arr[3],\n",
    "                               'area' : area,\n",
    "                               'confidence' : conf}\n",
    "                        df_preds = pd.DataFrame(df_dict, index=[0])\n",
    "                        df_preds_out = df_preds_out.append(df_preds, ignore_index=True)\n",
    "                \n",
    "    return df_preds_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minibatch(df, batch_num, batch_size):\n",
    "    #Get batch info\n",
    "    m = df.shape[0]\n",
    "    max_batchno = np.floor(m / batch_size) + 1.0\n",
    "    batch_num_act = batch_num % max_batchno\n",
    "    \n",
    "    #List container for indices selected\n",
    "    ind_list = []\n",
    "    \n",
    "    #Generate indices to select for this minibatch\n",
    "    for i in range(batch_size):\n",
    "        j = (batch_num_act*batch_size) + i\n",
    "        if j < m :\n",
    "            ind_list.append(j)\n",
    "    \n",
    "    #Select indices from dataframe\n",
    "    out_df = df.iloc[ind_list]\n",
    "    \n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generate_full_predframe(df, pred_mod, t_dict) :\n",
    "    m = df.shape[0]\n",
    "    \n",
    "    num = int(m / 2.0)\n",
    "    \n",
    "    for i in range(num):\n",
    "        pd_df = get_minibatch(df, i, 2)\n",
    "\n",
    "        if i == 0 :\n",
    "            full_pred_df = generate_pred_batch(pd_df, pred_mod, inverse = 1, inf_dict = t_dict )\n",
    "        else :\n",
    "            test_pred_df = generate_pred_batch(pd_df, pred_mod, inverse = 1, inf_dict = t_dict )\n",
    "            full_pred_df = full_pred_df.append(test_pred_df, ignore_index=True)\n",
    "\n",
    "    return full_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Output_pred_file(df_patients, df_preds_in, conf_thresh = 0.65) :\n",
    "    all_patients = df_patients['patientId'].copy()\n",
    "    m = len(all_patients)\n",
    "    \n",
    "    #Filtering rows by confidence threshhold\n",
    "    df_preds = df_preds_in[df_preds_in['confidence'] >=conf_thresh ]\n",
    "    \n",
    "    for i in range(m):\n",
    "        pred_str = ''\n",
    "        patient_id = all_patients[i]\n",
    "        all_preds = df_preds[df_preds['patientId'] == patient_id]\n",
    "        \n",
    "        n = len(all_preds)\n",
    "        \n",
    "        if n >= 1 :\n",
    "            for j in range(n):\n",
    "                pred_str += str(all_preds.iat[j, 6]) + ' ' + str(all_preds.iat[j, 1]) + ' ' + str(all_preds.iat[j, 2]) + ' ' + str(all_preds.iat[j, 3]) + ' ' + str(all_preds.iat[j, 4]) + ' '\n",
    "                \n",
    "        \n",
    "        sub_dict = {'patientId' : patient_id, \n",
    "                    'PredictionString' :pred_str }\n",
    "        \n",
    "        sub_df = pd.DataFrame(sub_dict, index=[0])\n",
    "        \n",
    "        if i == 0 :\n",
    "            pred_file_df = sub_df.copy()\n",
    "        else :\n",
    "            pred_file_df = pred_file_df.append(sub_df, ignore_index=True)\n",
    "    \n",
    "    return pred_file_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load everything else and generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#v2pick = open(os.path.join(TRAIN_PATH_CLEAN, 'val_2_tf.p'),'rb')\n",
    "#v2_tfm = pickle.load(v2pick)\n",
    "#v2pick.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tstpick = open(os.path.join(TEST_PATH_CLEAN, 'test_set_tfs.p'),'rb')\n",
    "#tst_tfm = pickle.load(tstpick)\n",
    "#tstpick.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstpick = open(os.path.join(TEST_PATH_CLEAN, 'test_set2_tfs.p'),'rb')\n",
    "tst_tfm = pickle.load(tstpick)\n",
    "tstpick.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_FULL = Generate_full_predframe(test_frame, test_mod, tst_tfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_csv_df = Output_pred_file(test_frame, test_FULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out_csv_df = Output_pred_file(tst_inv, test_again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_csv_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_csv_df.to_csv('unet_m6_stg2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
